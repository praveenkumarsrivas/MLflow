{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aebc516c",
   "metadata": {},
   "source": [
    "# Using the MLflow Client API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e38233",
   "metadata": {},
   "source": [
    "- Creating Experiments\n",
    "- Searching Experiments\n",
    "- Create a dataset about apples\n",
    "- Logging our first runs with MLflow\n",
    "- Logging Your First MLflow Model Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dff85067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T14:19:35.657652Z",
     "start_time": "2024-02-23T14:19:33.577384Z"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from pprint import pprint\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa5c9c87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T14:19:39.493519Z",
     "start_time": "2024-02-23T14:19:39.330644Z"
    }
   },
   "outputs": [],
   "source": [
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a72ae78e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T14:19:40.381807Z",
     "start_time": "2024-02-23T14:19:40.301897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1708585971334, experiment_id='0', last_update_time=1708585971334, lifecycle_stage='active', name='Default', tags={}>]\n"
     ]
    }
   ],
   "source": [
    "all_experiments = client.search_experiments()\n",
    "\n",
    "print(all_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "658011b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T14:19:46.103777Z",
     "start_time": "2024-02-23T14:19:46.090716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function PagedList.index(value, start=0, stop=9223372036854775807, /)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_experiments.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20215f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T10:23:33.906201Z",
     "start_time": "2024-02-23T10:23:33.892124Z"
    }
   },
   "outputs": [],
   "source": [
    "default_experiment = [\n",
    "    {\"name\": experiment.name, \"lifecycle_stage\": experiment.lifecycle_stage}\n",
    "    for experiment in all_experiments\n",
    "    if experiment.name == \"Default\"\n",
    "][0]\n",
    "\n",
    "pprint(default_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7bf401",
   "metadata": {},
   "source": [
    "## mlflow.search_run():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd638f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T10:43:32.850345Z",
     "start_time": "2024-02-23T10:43:32.485425Z"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"param1\",5)\n",
    "    mlflow.log_param(\"param2\",\"value\")\n",
    "    \n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\",0.85)\n",
    "    mlflow.log_metric(\"loss\",0.1)\n",
    "    \n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"param1\",5)\n",
    "    mlflow.log_param(\"param2\",\"some value\")\n",
    "    \n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\",0.95)\n",
    "    mlflow.log_metric(\"loss\",0.08)\n",
    "# Search for runs within the experiment with ID \"my_experiment\"\n",
    "# where the accuracy metric is greater than 0.9\n",
    "runs1 = mlflow.search_runs(experiment_ids=\"0\", filter_string=\"metrics.accuracy = 0.85\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6578084",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T10:49:39.368976Z",
     "start_time": "2024-02-23T10:49:39.349010Z"
    }
   },
   "outputs": [],
   "source": [
    "runs1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca6a031",
   "metadata": {},
   "source": [
    "# mlflow.client.MlflowClient.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ea221",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T11:05:10.651240Z",
     "start_time": "2024-02-23T11:05:10.375741Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import mlflow\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Start MLflow experiment\n",
    "mlflow.set_experiment(\"Hyperparameter Optimization for Random Forest Classifier\")\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Define hyperparameters to tune\n",
    "    n_estimators = 100\n",
    "    max_depth = 5\n",
    "\n",
    "    # Create and train Random Forest classifier\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Log hyperparameters and metrics\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import mlflow\n",
    "\n",
    "# Dummy customer churn data\n",
    "data = {\n",
    "    'age': [25, 35, 45, 55, 65],\n",
    "    'income': [50000, 60000, 70000, 80000, 90000],\n",
    "    'churn': [0, 1, 0, 1, 0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split features and target variable\n",
    "X = df[['age', 'income']]\n",
    "y = df['churn']\n",
    "\n",
    "# Start MLflow experiment\n",
    "mlflow.set_experiment(\"Logistic Regression for Customer Churn Prediction\")\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Create and train Logistic Regression model\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred = clf.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7757a24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T11:14:03.701800Z",
     "start_time": "2024-02-23T11:14:03.666726Z"
    }
   },
   "outputs": [],
   "source": [
    "experiments = client.search_experiments(filter_string=\"name LIKE '%Churn%'\")\n",
    "\n",
    "# Print information about the matching experiments\n",
    "print(\"Matching experiments:\")\n",
    "for experiment in experiments:\n",
    "    print(\"Experiment ID:\", experiment.experiment_id)\n",
    "    print(\"Experiment Name:\", experiment.name)\n",
    "    print(\"Artifact Location:\", experiment.artifact_location)\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14175163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T11:13:13.575793Z",
     "start_time": "2024-02-23T11:13:13.555721Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_id = \"296919399863335561\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c70ef2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T11:13:13.934351Z",
     "start_time": "2024-02-23T11:13:13.910299Z"
    }
   },
   "outputs": [],
   "source": [
    "# Search for experiments with the specified experiment ID\n",
    "experiments = mlflow.get_experiment(experiment_id)\n",
    "experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9bd814",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T11:16:10.657264Z",
     "start_time": "2024-02-23T11:16:10.618517Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e56f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
